{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "344b9de4",
   "metadata": {},
   "source": [
    "#### This little project is performed by SRUJAN HUKERIKAR .\n",
    "#### Date 21-8-2021 .\n",
    "#### project no: 003. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c74e08",
   "metadata": {},
   "source": [
    "# Data extraction and Text Analysis of Article "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b2954",
   "metadata": {},
   "source": [
    "### objective \n",
    "The objective of this project is to extract textual data artice from given URL and perform text analysis.\n",
    "#### 1. Sentimental analysis\n",
    "   Sentimental analysis is the process of determining whether a piece of writing is positive,negative, or neutral. The        below Algorithm is designed for use in Financial Texts.\n",
    "#### 2. Analysis of Readability \n",
    "   Analysis of Readability is calculated using the Gunning Fox index formula described below\n",
    "   Average Sentence Length = the number of words / the number of sentences\n",
    "   Percentage of Complex words = the number of complex words / the number of words\n",
    "   Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
    "#### 3. Average Number of Words Per Sentence\n",
    "   The formula for calculating is:\n",
    "   Average Number of Words Per Sentence = the total number of words / the total number of sentences.\n",
    "#### 4. Complex Word Count\n",
    "   Complex words are words in the text that contain more than two syllables.\n",
    "#### 5. Word Count\n",
    "   We count the total cleaned words present in the text by\n",
    "   a) removing the stop words (using stopwords class ofnltk package).\n",
    "   b) removing any punctuations like ? ! , . from the word before counting.\n",
    "#### 6. Syllable Count Per Word\n",
    "   We count the number of Syllables in each word of the text by counting the vowels present in\n",
    "   each word. We also handle some exceptions like words ending with \"es\",\"ed\" by not counting\n",
    "   them as a syllable.\n",
    "#### 7. Personal Pronouns\n",
    "    To calculate Personal Pronouns mentioned in the text, we use regex to find the counts of the\n",
    "    words - I, 'we,\" \"my,\" \"ours,\" and \"us\". Special care is taken so that the country name US is not included in the list.\n",
    "#### 8.  Average Word Length\n",
    "    Average Word Length is calculated by the formula:\n",
    "    sum of the total number of characters in each word/Total number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2c2c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 91: expected 1 fields, saw 2\\n'\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Srujan\n",
      "[nltk_data]     Hukerikar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Srujan\n",
      "[nltk_data]     Hukerikar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!pip install newspaper3k\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./StopWords.txt', error_bad_lines=False)\n",
    "import nltk\n",
    "import newspaper\n",
    "nltk.download('punkt')\n",
    "from newspaper import Article\n",
    "article_name = Article(\"https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/\", language=\"en\")\n",
    "article_name.download()\n",
    "article_name.parse()\n",
    "article_name.nlp()\n",
    "article_name.text\n",
    "article=article_name.text\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words=data\n",
    "text_tokens = word_tokenize(article)\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "final_article=\" \".join(tokens_without_sw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17afb82d",
   "metadata": {},
   "source": [
    "# extraction of article from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e9d6a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction\n",
      "\n",
      "AI is rapidly evolving in the employment sector, particularly in matters involving business and finance. Finance, management, economics, and accounting are now among the most popular university courses globally; particularly at the graduate level, due to their high employability. However, the evolution of machinery in industries is changing that. According to research, 230,000 jobs in these sectors may be replaced by AI agents in the next 5 years. This is due to the nature of the work, as employees are responsible for tasks such as data analysis and keeping track of numerical information; which machines excel at. Large, complicated data sets can be analyzed faster and more efficiently by AI-powered computers than by people. Algorithmic trading procedures that produce automated deals are less likely to be produced without minute errors when undertaken by humans. In such matters involving industrial work, a subsection of artificial intelligence is used; namely, machine learning.\n",
      "\n",
      "Machine learning is a term used for the application of artificial intelligence (AI) in systems, which involves them assimilating and processing information by gaining experience. It is mainly concerned with the development of technology and computer programs.\n",
      "\n",
      "Its improvement process is mainly divided into seven steps; which start with the collection of data. This data can be collected from an internal database or perhaps an IoT structure. The second and most time-consuming step is cleaning, preparing, and rearranging the data; which involves the recognition of outliers, trends, and missing information so that the outcome is as accurate as possible. The third step consists of formatting data; which is useful if you source your information from a variety of sources. Step four is where AI comes into place. Self-service data processing tools may be useful if they provide intelligent services for matching data attributes from distinct databases and intelligently integrating them. The data is then arranged to better represent a specific pattern. Lastly, the data is divided into two sets: one for training the algorithm and one for analysis.\n",
      "\n",
      "There are three types of machine learning; supervised, unsupervised, and reinforcement learning. The most common of the bunch is supervised machine learning; which is based on accurately labeled data. The machine is given a collection of information, including the outcome of the operation. The rest of the information is referred to as ‘input features’, which ‘supervises’ the machine by guiding it to establish the connections between the variants.\n",
      "\n",
      "In the case of unsupervised learning, the machine isn’t given labeled sets of data to be divided into, allowing it to recognize and create its own patterns within the information provided. Since computers have the capabilities of identifying distinguished similarities, this method helps with the classifying of such data.\n",
      "\n",
      "Reinforcement learning comprises experience-based learning. Similar to people, they learn due to a reward and punishment system based on their actions.\n",
      "\n",
      "These variations of system learning have recently been integrated into business and finance, which is elaborated on in the following passages.\n",
      "\n",
      "Machine learning in finance and banking\n",
      "\n",
      "There are many ways in which machine learning is used in finance and banking. The most common place it is used is to detect any frauds. Fraud is the most common problem in financial service companies and it accounts for billions of dollars in misfortune each year. The most common frauds are credit or debit card usage by a stranger, document forgery, and mortgage fraud.\n",
      "\n",
      "Usually, finance companies keep an enormous amount of their data stored online, and it increases the risk of information being accessed without authorization. With expanding innovative headway, misrepresentation in the monetary business is currently viewed as a high danger to significant information. Fraud recognition frameworks in the past were planned dependent on a bunch of rules, which could be effortlessly be bypassed by current fraudsters. Therefore, most companies today leverage machine learning to combat fraudulent financial transactions.\n",
      "\n",
      "Machine learning works by looking over enormous informational indexes to distinguish unique or suspicious activities for additional examination by security groups. It works by looking at an exchange against other information focuses – like the client’s record history, IP address, area, and so forth. Depending on the type of exchange taking place, the program can automatically refuse a withdrawal or purchase until the person makes a decision.\n",
      "\n",
      "Examples of fraud detection software used by banks include Feedzai, Data visor, and Teradata\n",
      "\n",
      "Machine learning is also used in algorithmic trading, portfolio management, loan underwriting, chatbots, and improving customer service.\n",
      "\n",
      "Algorithmic trading is an interaction for executing orders using computerized and pre-modified exchanging guidelines to represent factors like value, timing, and volume. An algorithm is a set of directions for solving a problem. Computer calculations send little parts of the full request to the market over the long run.\n",
      "\n",
      "In contrast to human dealers, algorithmic exchanging can investigate enormous volumes of information every day and therefore make thousands of trades every day. Machine learning settles on quick exchanging choices, which gives human traders a benefit over the market normal. Likewise, algorithmic exchanging doesn’t settle on exchanging choices dependent on feelings, which is a typical constraint among human dealers whose judgment might be influenced by feelings or individual desires. The exchanging technique is generally utilized by multifaceted investment administrators and monetary foundations to automate trading activities.\n",
      "\n",
      "In the banking industry, organizations access a large number of shopper information, with which machine learning can be prepared to work in order to simplify the underwriting process. Machine learning calculations can settle on speedy choices on endorsing and credit scoring, and save organizations both time and monetary assets that are utilized by people.\n",
      "\n",
      "Data scientists can train algorithms on how to analyze millions of consumer data to coordinate with information records, search for interesting special cases, and settle on a choice on whether a shopper meets all requirements for an advance or protection. For instance, the calculation can be prepared on the most proficient method to examine shopper information, like age, pay, occupation, and the buyer’s credit conduct.\n",
      "\n",
      "The benefits of machine learning\n",
      "\n",
      "As with any form of revolutionary technology, the usage of machine learning has been debated over as its beneficial properties have been weighed against the possible disadvantages. It’s been observed that upon correct usage, it may be used to solve a wide range of business challenges and anticipate complicated customer behavior. We’ve also seen several of the largest IT conglomerates, such as Google, Amazon, and Microsoft, introduce Cloud Machine Learning platforms.\n",
      "\n",
      "Technology vs Human intelligence\n",
      "\n",
      "In terms of business, ML can aid businesses by identifying consumer’s demands and formulate a pattern based on them; allowing companies to reach out to such consumers and maximize their sales. It eliminates the need for expenses on some maintenance by reducing the risks associated with unexpected breakdowns and minimizes wasteful costs to the firms. Historical data, a process visualization tool, a flexible analytical environment, and a feedback loop may all be used to build an ML architecture. The input of data is another agitating chore for businesses in the present, which is where machine learning can step in for manual labor. This eradicates the possibility of errors caused by manual labor causing disruptions and provides employees with extra time to handle other tasks.\n",
      "\n",
      "In the financial sector, machine learning is already utilized for portfolio management, algorithmic trading, loan underwriting, and fraud detection. Chatbots and other conversational interfaces for security, customer support, and sentiment analysis will be among the future uses of ML in banking. Another aspect of business involving artificial intelligence includes image recognition, which entails a system or program that recognizes objects, people, places, and movements in photos. It identifies photographs using an imaging system and machine recognition tech with artificial intelligence and programmed algorithms.\n",
      "\n",
      "The downfalls of machine learning\n",
      "\n",
      "With all the benefits of its advancement, machine learning isn’t the most perfect thing. There are several disadvantages which are information acquisition, time and resources and high errors, and wrong interpretations. One of the major hurdles is the amount of finance needed to invest in machine learning for it to be a successful project. More issues have to do with the fact that AI requires gigantic informational indexes to train on, and these ought to be unbiased, and of good quality. There can likewise be times where they have to wait for that new information to be produced. Machine learning needs sufficient opportunity to do the calculations to learn and adequately to satisfy their accuracy and relevancy. It also needs huge resources to work. This can mean extra requirements for the computer to work. Another significant problem is the capacity to precisely decipher the results produced by the calculations. You should likewise cautiously pick the algorithms to get the wanted results.\n",
      "\n",
      "Conclusion\n",
      "\n",
      "There have been various reports in the past and current years which claim that a significant piece of the human labor force will be replaced via robots and machines in the years to come. With excessive innovative work being led in the field of computerized reasoning, many dread that a significant job crisis will unfurl since numerous positions are all the more precisely and productively performed with the use of machines. In countries like Japan, mainly computer programs and AI is used in the secondary and tertiary sectors. From cleaning the house to depositing money in banks, everything is done by AI. However, AI cannot replace humans in the future. Humans have several capabilities which, even after several technological advancements a machine would not be able to have. These capabilities include creative thinking and creative problem solving, and human connection. For example, when a child goes to a doctor to get an injection, a nurse always relaxes the child to not be afraid of the needle. A machine’s touch would not be able to soothe a child. Another example could be how humans tend to share things with each other and be open about it, a machine will not be able to do so since it is only programmed to things it has been told to do. Like computers, AI will not replace us but would however complement us to make daily work easier and less time-consuming. Without humans themselves, there is no future for AI.\n",
      "\n",
      "Blackcoffer Insights 29: Amara Arora and Vaanya Kaushal, Scottish High International School\n"
     ]
    }
   ],
   "source": [
    "print(article_name.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb4205",
   "metadata": {},
   "source": [
    "# Summerization of Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ad4160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning in finance and bankingThere are many ways in which machine learning is used in finance and banking.\n",
      "We’ve also seen several of the largest IT conglomerates, such as Google, Amazon, and Microsoft, introduce Cloud Machine Learning platforms.\n",
      "In the financial sector, machine learning is already utilized for portfolio management, algorithmic trading, loan underwriting, and fraud detection.\n",
      "The downfalls of machine learningWith all the benefits of its advancement, machine learning isn’t the most perfect thing.\n",
      "Machine learning needs sufficient opportunity to do the calculations to learn and adequately to satisfy their accuracy and relevancy.\n"
     ]
    }
   ],
   "source": [
    "print(article_name.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40e67c",
   "metadata": {},
   "source": [
    "# Generating Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2aa3cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'learning', 'ai', 'data', 'used', 'exchanging', 'information', 'future', 'work', 'machine', 'finance', 'robots', 'jobs', 'humans']\n"
     ]
    }
   ],
   "source": [
    "print(article_name.keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4e27c",
   "metadata": {},
   "source": [
    "# Removing StopWords from Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f22d24fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 91: expected 1 fields, saw 2\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERNST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YOUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DELOITTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOUCHE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KPMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRICEWATERHOUSECOOPERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14100</th>\n",
       "      <td>GUO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14101</th>\n",
       "      <td>LIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14102</th>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14103</th>\n",
       "      <td>GAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14104</th>\n",
       "      <td>LIANG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14105 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ERNST\n",
       "0                       YOUNG\n",
       "1                    DELOITTE\n",
       "2                      TOUCHE\n",
       "3                        KPMG\n",
       "4      PRICEWATERHOUSECOOPERS\n",
       "...                       ...\n",
       "14100                     GUO\n",
       "14101                     LIN\n",
       "14102                      HE\n",
       "14103                     GAO\n",
       "14104                   LIANG\n",
       "\n",
       "[14105 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./StopWords.txt', error_bad_lines=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6437e",
   "metadata": {},
   "source": [
    "# Dictionary of positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4550e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = pd.read_csv('./positive-words.txt', error_bad_lines=False)\n",
    "negative_words = pd.read_csv('./negative-words.txt', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "238dbc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abundance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abundant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accessable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>youthful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>zeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>zenith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>zest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>zippy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2005 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              a+\n",
       "0         abound\n",
       "1        abounds\n",
       "2      abundance\n",
       "3       abundant\n",
       "4     accessable\n",
       "...          ...\n",
       "2000    youthful\n",
       "2001        zeal\n",
       "2002      zenith\n",
       "2003        zest\n",
       "2004       zippy\n",
       "\n",
       "[2005 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15c744b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2-faced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abolish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abominable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abominably</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>zaps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>zealot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4779</th>\n",
       "      <td>zealous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>zealously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>zombie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4782 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2-faced\n",
       "0        2-faces\n",
       "1       abnormal\n",
       "2        abolish\n",
       "3     abominable\n",
       "4     abominably\n",
       "...          ...\n",
       "4777        zaps\n",
       "4778      zealot\n",
       "4779     zealous\n",
       "4780   zealously\n",
       "4781      zombie\n",
       "\n",
       "[4782 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46b678cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive score : 0.144\n",
      "negative score : 0.089\n",
      "polarity score : 0.06774791359842908\n",
      "subjectivity score : 0.5226485027000489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Srujan\n",
      "[nltk_data]     Hukerikar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentence length:  13.552941176470588\n",
      "percentage of complex words 37.15277777777778\n",
      "fog index : 20.28228758169935\n",
      "Avarage word count per sentence : 13.411764705882353\n",
      "complex word count 428\n",
      "word count 1152\n",
      "syllable count per word 1.8394097222222223\n",
      "count of personal Pronous 690\n",
      "Avarage word length: 6.167543859649123\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from textstat.textstat import textstatistics\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "  \n",
    "\n",
    "def pos_score(text):\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(text)\n",
    "    return score['pos']\n",
    "\n",
    "\n",
    "def negative_score(text):\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(text)\n",
    "    return score['neg']\n",
    "\n",
    "\n",
    "def getSubjectivity(text):\n",
    "   return TextBlob(text).sentiment.subjectivity\n",
    "def getPolarity(text):\n",
    "   return TextBlob(final_article).sentiment.polarity\n",
    "\n",
    "def word_count(text):\n",
    "    sentences = break_sentences(text)\n",
    "    words = 0\n",
    "    for sentence in sentences:\n",
    "        words += len([token for token in sentence])\n",
    "    return words\n",
    " \n",
    "def sentence_count(text):\n",
    "    sentences = break_sentences(text)\n",
    "    return len(sentences)\n",
    "\n",
    "\n",
    "def syllables_count(word):\n",
    "    return textstatistics().syllable_count(word)\n",
    "\n",
    "\n",
    "def break_sentences(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    return list(doc.sents)\n",
    "\n",
    "\n",
    "def avg_sentence_length(text):\n",
    "    words = word_count(text)\n",
    "    sentences = sentence_count(text)\n",
    "    average_sentence_length = float(words / sentences)\n",
    "    return average_sentence_length\n",
    "\n",
    "\n",
    "def complex_words(text):\n",
    "     \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    words = []\n",
    "    sentences = break_sentences(text)\n",
    "    for sentence in sentences:\n",
    "        words += [str(token) for token in sentence]\n",
    "    complex_words_set = set()\n",
    "     \n",
    "    for word in words:\n",
    "        syllable_count = syllables_count(word)\n",
    "        if word not in nlp.Defaults.stop_words and syllable_count >= 2:\n",
    "            complex_words_set.add(word)\n",
    " \n",
    "    return len(complex_words_set)\n",
    "def Avg_num_of_words_per_sentence(text):\n",
    "    line_count=0\n",
    "    words= text.split()\n",
    "    word_count=len(words)\n",
    "    for line in text:\n",
    "        line_count+=1\n",
    "    average_words=word_count/ sentence_count(text)\n",
    "    return average_words\n",
    "\n",
    "def Avg_word_length(text):\n",
    "    text=text.split()\n",
    "    res = sum(map(len, text))/float(len(text))\n",
    "    return res\n",
    "\n",
    "def syllables_count(word):\n",
    "    return textstatistics().syllable_count(word)\n",
    "\n",
    "def percentage_complex_word(text):\n",
    "    per_diff_words = ( complex_words(final_article)/ word_count(final_article) * 100)\n",
    "    return per_diff_words\n",
    "\n",
    "def fog_index(text):\n",
    "    grade = 0.4 * (avg_sentence_length(text) + percentage_complex_word(text))\n",
    "    return grade\n",
    "\n",
    "def personal_pronous(text):\n",
    "    pronounRegex = re.compile(r'I|we|my|ours|us',re.I)\n",
    "    pronouns = pronounRegex.findall(text)\n",
    "    result=len(pronouns)\n",
    "    return result\n",
    "\n",
    "def syllable_count_per_word():\n",
    "    res=syllables_count(final_article)/word_count(final_article)\n",
    "    return res\n",
    "print(\"positive score :\",pos_score(final_article))\n",
    "print(\"negative score :\",negative_score(final_article))\n",
    "print(\"polarity score :\",getPolarity(final_article))\n",
    "print(\"subjectivity score :\",getSubjectivity(final_article))\n",
    "print(\"Average sentence length: \",avg_sentence_length(final_article))\n",
    "print(\"percentage of complex words\",percentage_complex_word(final_article))\n",
    "print(\"fog index :\",fog_index(final_article))\n",
    "print(\"Avarage word count per sentence :\",Avg_num_of_words_per_sentence(final_article))\n",
    "print(\"complex word count\",(complex_words(final_article)))\n",
    "print(\"word count\",word_count(final_article))\n",
    "print(\"syllable count per word\",syllable_count_per_word())\n",
    "print(\"count of personal Pronous\",personal_pronous(final_article))\n",
    "print(\"Avarage word length:\",Avg_word_length(final_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7143128",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1980631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47dec4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
